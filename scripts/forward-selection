#!/usr/bin/env python

import collections
import heapq
import json
import math
import numpy as np
import operator
import os
import pickle
import random
import redis
import scipy
from sklearn.linear_model import Ridge
import signal
import socket
import subprocess
import sys
import time
import uuid
import xml.etree.ElementTree as ET

class CommonEqualityMixin(object):
  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
  def __ne__(self, other):
    return not self.__eq__(other)

# sorry, global
TEMPLATE_INFO = None  # Stores info about what templates/stages we're optimizing over
FAILED_SCORE = 0.0
SER_Q_PATH = None
SER_Q = None


class Feature(CommonEqualityMixin):
  def __init__(self, stage, syntax_mode, label, templates=[]):
    ''' label is just a priveledged template that has high selectivitity and must be there '''
    if type(templates) is str:
      templates = [templates]
    assert type(label) is str
    assert type(templates) is list # of strinsgs
    self.stage = stage
    self.syntax_mode = syntax_mode
    self.label = label
    self.templates = templates
    self.templates.sort()

  def __str__(self):
    st = self.stage + '-' + self.syntax_mode
    return "*".join([st, self.label] + self.templates)

  def estimate_cardinality(self):
    c = TEMPLATE_INFO.cardinality(self.label, self.stage, self.syntax_mode)
    for t in self.templates:
      c *= TEMPLATE_INFO.cardinality(t, self.stage, self.syntax_mode)
    assert type(c) is int or type(c) is long
    return c

  def propose_modification(self):
    # the higher the estimated cardinality, the greater the chance of
    # removing a template
    # e.g. cardinality = 100  -> p(shrink) = 0.500
    #      cardinality = 4    -> p(shrink) = 0.167
    #      cardinality = 400  -> p(shrink) = 0.667
    #      cardinality = 4000 -> p(shrink) = 0.863 (only if #templates > 1 though)
    card = pow(self.estimate_cardinality(), 0.5)
    p_shrink = card / (card + 10.0)
    if len(self.templates) > 1 and random.random() < p_shrink:
      # add a new template
      xs = [x for x in TEMPLATE_INFO.basic_templates() if x not in self.templates]
      if len(xs) > 0:
        return Feature(self.stage, self.syntax_mode, self.label, self.templates + [random.choice(xs)])
      else:
        raise Exception('cant extend this Feature any further')
    else:
      # remove a template
      assert len(self.templates) >= 2
      tmpl = random.sample(self.templates, len(self.templates) - 1)
      return Feature(self.stage, self.syntax_mode, self.label, tmpl)


class FeatureSet(object):
  def __init__(self, features=[], derived_from=None):
    self.features = features
    self.derived_from = derived_from

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.features == other.features

  def __ne__(self, other):
    return not self.__eq__(other)

  def estimate_cardinality(self, stage=None):
    ''' Returns a dict with stage names as keys and int/long values '''
    cards = collections.defaultdict(lambda: 1)
    for f in self.features:
      cards[f.stage] = cards[f.stage] * f.estimate_cardinality()
    if stage:
      return cards[stage]
    else:
      return cards

  def stages(self):
    s = set()
    for f in self.features:
      s.add(f.stage)
    return list(s)

  def labels(self, stage=None):
    ''' If a stage is not provided, we union over stages '''
    labs = set()
    for f in self.features:
      if stage is None or f.stage == stage:
        labs.add(f.label)
    return list(labs)

  def propose_modification(self):
    ''' Returns a new FeatureSet derived from this feature set '''
    debug = True
    stage = random.choice(TEMPLATE_INFO.stages())
    card = self.estimate_cardinality(stage)
    l = 0.3		# interpolation between cardinality (1) and #features (0)
    alpha = 0.2
    beta = 200.0
    gamma = 3.0
    p_add_feature = l * beta / (beta + pow(card, alpha)) \
      + (1.0 - l) * (gamma / (gamma + len(self.features)))
    if random.random() < p_add_feature:
      f = self.new_feature()
      if debug:
        print '[propose_modification add_new_feature] len(self.features) =', \
          len(self.features), 'stage =', stage, 'cardinality =', card, \
          'p_add_features =', p_add_feature, 'new_feature =', f
      return FeatureSet(self.features + [f], derived_from=self)
    else:
      # modify and replace a feature that is already in this feature set
      try:
        i = random.randrange(len(self.features))
        f = self.features[i].propose_modification()
        if debug:
          print '[propose_modification modify_feature] len(self.features) =', \
            len(self.features), 'stage =', stage, 'cardinality =', card, \
            'p_add_features =', p_add_feature, '\t', self.features[i], '=>', f
        return FeatureSet([f] + self.features[:i] + self.features[i+1:], derived_from=self)
      except:
        return self.propose_modification()

  def new_feature(self):
    ''' creates a feature that is not already in this feature set '''
    # prefer adding features with small number of templates
    stage = random.choice(TEMPLATE_INFO.stages())
    syntax_mode = self.syntax_mode()
    label = random.choice(TEMPLATE_INFO.labels_for(stage, syntax_mode))
    templates = random.choice(TEMPLATE_INFO.basic_templates())
    f = Feature(stage, syntax_mode, label, templates)
    if f in self.features:
      return self.new_feature()
    else:
      print '[new_feature] stage =', stage
      print '[new_feature] syntax_mode =', syntax_mode
      print '[new_feature] label =', label
      print '[new_feature] templates =', templates
      return f

  def syntax_mode(self):
    assert len(self.features) > 0
    return self.features[0].syntax_mode

  def __str__(self):
    return "<FeatureSet %s>" % (', '.join([str(x) for x in self.features]))

  def config_string(self):
    return "+".join([str(x) for x in self.features])

class Config(CommonEqualityMixin):
  ''' A full specification of a FN parsing model '''
  def __init__(self, feature_set, settings_dict, regularizer_dict, batch_size_dict, passes_dict):
    self.feature_set = feature_set

    self.regularizer_dict = regularizer_dict
    for k, v in regularizer_dict.iteritems():
      assert type(k) is str # Name of the stage
      assert type(v) is int # Natural log of the regularizer

    self.batch_size_dict = batch_size_dict
    for k, v in batch_size_dict.iteritems():
      assert type(k) is str # Name of the stage
      assert type(v) is int # Batch size

    self.passes_dict = passes_dict
    for k, v in passes_dict.iteritems():
      assert type(k) is str # Name of the stage
      assert type(v) is int # Number of training passes

    self.params = {}
    self.params['randomSeed'] = '9001'
    self.params.update(settings_dict)

  def stages(self):
    s1 = set(self.regularizer_dict.keys())
    s2 = set(self.features.stages())
    assert s1.issuperset(s2)
    return list(s1)

  def __str__(self):
    return "<Config features=%s regularizer=%s params=%s>" % \
      (str(self.feature_set), str(self.regularizer_dict), str(self.params))

def mutate_config(config):
  ''' Returns a function from Config to Config '''
  next_fs = config.feature_set.propose_modification()
  cur_card = config.feature_set.estimate_cardinality()
  next_card = next_fs.estimate_cardinality()
  print '[mutate_config] cardinality: ', cur_card, ' => ', next_card
  # cardinality is now a dict with stages as keys
  # regularizer is too
  # for each stage, decide if you want to change the regularizer or not
  alpha = 15000
  beta = 1.5
  gamma = 0.25   # p(change regularizer irrespective of cardinality)
  children = [Config(next_fs, config.params, config.regularizer_dict, config.batch_size_dict, config.passes_dict)]
  for stage in TEMPLATE_INFO.stages():
    cc = cur_card[stage]
    nc = next_card[stage]
    dc = nc - cc
    if dc > alpha or dc / cc > beta or random.random() < gamma:
      # stronger regularizer
      reg = {}
      reg.update(config.regularizer_dict)
      reg[stage] = reg[stage] + 1
      children.append(Config(next_fs, config.params, reg, config.batch_size_dict, config.passes_dict))
    if dc < -alpha or dc / cc < -beta or random.random() < gamma:
      # weaker regularizer
      reg = {}
      reg.update(config.regularizer_dict)
      reg[stage] = reg[stage] - 1
      children.append(Config(next_fs, config.params, reg, config.batch_size_dict, config.passes_dict))

  # TODO try increasing/decreasing the number of passes

  return children



class ConfigQueue(object):
  '''
  An infinite queue of items. A seed set of items should be pushed onto the queue
  to begin with, but after that this queue will generate new items by calling
  propose_modification on existing items. Remember to call observe_score to let this
  queue know what are good items and which are bad.
  '''
  def __init__(self, mutation_function, greediness=1.0):
    self.mutation_function = mutation_function  # item -> [item]
    self.greediness = greediness
    self.item2score = {}    # item -> score for popped items
    self.waiting = []       # List of items that should be popped before mutating scored items

  def _pick(self, greediness):
    debug = False
    # Find the max score
    m = max(self.item2score.values())
    # Compute regret for the other scores
    weights = []
    items = []
    z = 0.0
    for item, s in self.item2score.iteritems():
      regret = (m - s) * 10.0
      w = math.exp(-regret * greediness)
      weights.append(w)
      items.append(item)
      z += w
    t = random.random() * z
    if debug:
      print '[pick] z =', z, 't =', t
    # Randomly sample
    c = 0.0
    for i in range(len(weights)):
      c += weights[i]
      if debug:
        print '[pick]', items[i], 'has score', c
      if c >= t:
        print '[pick] chose', items[i]
        return items[i]
    # Should never get here
    print '[pick] scored_feature_sets:', self.item2score
    print '[pick] weights:', weights
    assert False

  def show_state(self, k=10):
    print '[show_state]', len(self.item2score), 'observations'
    best = sorted(self.item2score.items(), key=operator.itemgetter(1), reverse=True)
    i = 1
    for item, score in best[:k]:
      print "[show_state] %dth best\t%.3f\t%s" % (i, score, item)
      i += 1

  def observe_score(self, score, name, item):
    ''' Record the score of a given config/item '''
    print '[observe_score] score =', score, 'item =', item
    assert type(score) is float
    assert type(name) is str
    assert type(item) is not str  # TODO for debugging, in the future this could technically be a string
    if item in self.item2score:
      if self.item2score[item] == FAILED_SCORE:
        print ("[observe_score] WARN: may need to sleep longer, " \
          "%s/%s was originally deemed failed but later reported a score of %f") \
          % (item, name, score)
      else:
        raise Exception(item + ' had a score of ' \
          + str(self.item2score[item]) \
          + ' but you tried to observe the score ' + str(score))
    self.item2score[item] = score
    # print the biggest weights
    if len(self.item2score) % 10 == 0:
      self.show_state()

  def seed(self, item):
    ''' Like push, but this item is special in that we will use it as the seed
    for all items until we start receiving scores back '''
    print '[seed] seeding', item, 'with score', FAILED_SCORE
    self.push(item)
    self.observe_score(FAILED_SCORE, 'seed' + str(len(self.item2score)), item)

  def push(self, item):
    ''' Push an item onto the queue which must be run before
    propose_modification's are considered '''
    self.waiting.append(item)

  def pop(self):
    ''' Returns a pushed item if there is one, otherwise chooses
    a scored item and mutates it with propose_modification '''
    if self.waiting:
      return self.waiting.pop()
    else:
      if len(self.item2score) == 0:
        raise Exception('you must seed some items using push so there is something to mutate')
      tries = 0
      max_tries = 100
      while tries < max_tries:
        # g->0 as we run out of tries
        g = self.greediness * (max_tries - tries) / float(max_tries)
        parent = self._pick(g)
        children = self.mutation_function(parent)
        dont_generate = set(self.waiting + self.item2score.keys())
        feasible = [c for c in children if c not in dont_generate]
        if len(feasible) < len(children):
          for c in (set(children) - set(feasible)):
            print '[pop] pruned', c
        if feasible:
          random.shuffle(feasible)
          while len(feasible) > 1:
            self.push(feasible.pop())
          return feasible.pop()
        else:
          tries += 1
      print '[pop] couldn\'t generate a new configuration'
      return None


class SgeJobTracker(object):
  ''' A job tracker that asks qstat for the jobs that are
  running and spawns jobs with qsub '''
  def can_submit_more_jobs(self):
    return len(self.jobs_queued()) < 30

  def jobs(self):
    '''
    name_predicate should be a lambda that takes a string (name)
    and returns true if the job should be kept.
    This method skips over any jobs that are marked as QLOGIN,
    so name_predicate need not filter those out.
    Returns a list of job names.
    '''
    xml = subprocess.check_output(['qstat', '-u', 'twolfe', '-xml'])
    xml = ET.fromstring(xml)
    assert xml.tag == 'job_info'
    # NOTE: wow this is really bad...
    # SGE reports *running* jobs in a list called 'queue_info'
    # and reports *queued* jobs in a list called 'job_info'
    for info_name in ['job_info', 'queue_info']:
      info = xml.find(info_name)
      assert info is not None
      # NOTE: each 'job_list' is actually a job
      # not a list of jobs as the name would suggest
      for j in info.findall('job_list'):
        #print 'j.tag', j.tag
        state = j.find('state').text    # e.g. 'r' or 'qw'
        name = j.find('JB_name').text
        #print '[sge jobs]', state, name
        if name == 'QLOGIN':
          continue
        yield (state, name)

  def jobs_running(self):
    ''' returns a list of job names '''
    return [name for state, name in self.jobs() if state == 'r']

  def jobs_queued(self):
    ''' returns a list of job names '''
    return [name for state, name in self.jobs() if state == 'qw']

  def spawn(self, name, args):
    cmd = ['qsub', '-N', name, 'ForwardSelectionWorker.qsub', name]
    for k, v in args.iteritems():
      cmd += [k, v]
    print '[sge spawn] cmd =', ["'" + x + "'" for x in cmd]
    subprocess.Popen(cmd)
    time.sleep(0.2)


class LocalJobTracker(object):
  '''
  mock job tracker which uses redis instead of qsub
  if debug is true, this will call scripts/dummy-forward-selection-job
  else this will call the actual experiment
  '''
  def __init__(self, debug=False, max_concurrent_jobs=2):
    self.key = 'dummy-job-tracker.jobs'
    self.redis = redis.StrictRedis(host='localhost', port=6379, db=0)
    self.debug = debug
    self.max_concurrent_jobs = max_concurrent_jobs

  def remove_all_jobs(self):
    ''' ensures that there are no jobs running (for testing) '''
    self.redis.delete(self.key)

  def can_submit_more_jobs(self):
    return len(self.jobs_running()) < self.max_concurrent_jobs

  def jobs_running(self):
    # TODO this won't work in cases where jobs die!
    # qsub can handle this, but to remove from redis queue, we've been assuming things finish
    return self.redis.lrange(self.key, 0, -1)

  def set_job_done(self, name):
    print '[set_job_done] name=' + name
    self.redis.lrem(self.key, 0, name)

  def jobs_queued(self):
    return []

  # NOTE this implementation is a bit annoying because stdout from the spawned process
  # dumps into the main process's stdout, BUT this is only a problem locally. This appears
  # difficult to solve in python because there is no way to properly close the file that
  # you would route stdout to.
  def spawn(self, name, args):
    ''' args should be a dictionary of values to pass to grid.Runner '''
    self.redis.rpush(self.key, name)
    if self.debug:
      raise Exception('need to update args for dummy-forward-selection-job')
      subprocess.Popen(['scripts/dummy-forward-selection-job'] + args)
    else:
      cp = subprocess.check_output(['find', 'target/', '-iname', '*.jar']).strip()
      cp = ':'.join([x.strip() for x in cp.split('\n')])
      #cp = 'target/classes:' + cp
      cmd = ['java', '-Xmx4G', '-ea', '-cp', cp]
      cmd += ['-XX:+UseG1GC', '-XX:G1ReservePercent=2', '-XX:ConcGCThreads=1', '-XX:ParallelGCThreads=1']
      cmd.append('edu.jhu.hlt.fnparse.experiment.grid.Runner')
      cmd.append(name)
      for k, v in args.iteritems():
        cmd += [k, v]
      print '[spawn] about to spawn:', ' '.join(["'" + x + "'" for x in cmd])
      subprocess.Popen(cmd)


class ForwardSelection:
  def __init__(self, name, working_dir, job_tracker, config_q, \
      poll_interval=3.0, max_train_size=None, max_num_jobs=None, \
      redis_config={'channel':'forward-selection', 'host':'localhost', 'port':'6379', 'db':'0'}):
    print '[ForwardSelection] attempting to use redis server at', redis_config
    self.name = name
    self.working_dir = working_dir  # where workers are allowed to dump results
    self.redis_config = redis_config
    self.job_tracker = job_tracker  # talks to qsub
    self.config_q = config_q
    self.name2item = {}
    self.poll_interval = poll_interval
    self.dispatched = set()         # names of the jobs that (should be) running
    self.max_train_size = max_train_size  # limit on size of training data to make things faster
    self.max_num_jobs = max_num_jobs      # limit on how many total jobs can be submitted

  def parse_message(self, data):
    '''
    parses a message from the experiment over redis pubsub
    and returns a tuple of (config, score)
    '''
    toks = data.split('\t', 2)
    assert len(toks) == 3
    score = float(toks[0])
    name = toks[1]
    config = toks[2]
    return (score, name, config)

  def start_job(self):
    ''' returns a unique job name and updates self.name2item '''
    # TODO move this to a separate method that is passed in, like mutate
    item = self.config_q.pop()
    if item:
      name = "fs-%s-%d" % (self.name, len(self.name2item))
      self.name2item[name] = item
      wd = os.path.join(self.working_dir, name + '-wd')
      if not os.path.isdir(wd):
        os.mkdir(wd)
      # Parameters for cross-validation
      # NOTE These settings should be here because there are not config-specific.
      # This is a problem because the jobs responds with a config string to uniquely id itself,
      # but the job doesn't know the difference between config and params...
      # Have to use config for id because job name is not known until after the job is launched.
      # WAIT, couldn't I just use my job name?
      K = 2
      p = 0.15
      cmd = {}
      cmd['KpTrainDev'] = "%d %f" % (K, p)
      if self.max_train_size:
        cmd['MaxTrainSize'] = str(self.max_train_size)
      rf = os.path.join(wd, 'results.txt')
      cmd['resultReporter'] = "redis:%s,%s,%s\tfile:%s" % \
        (self.redis_config['host'], self.redis_config['channel'], self.redis_config['port'], rf)
      cmd['workingDir'] = wd
      cmd['features'] = item.feature_set.config_string()
  
      for stage, regularizer in item.regularizer_dict.iteritems():
        cmd['regularizer.' + stage] = str(math.exp(regularizer))

      for stage, batch_size in item.batch_size_dict.iteritems():
        cmd['batchSize.' + stage] = str(batch_size)

      for stage, passes in item.passes_dict.iteritems():
        cmd['passes.' + stage] = str(passes)

      cmd.update(item.params)
      self.job_tracker.spawn(name, cmd)
      self.dispatched.add(name)
      print '[start_job] name =', name
      print '[start_job] params =', item.params
      return name
    else:
      print '[start_job] there are no more jobs, returning None'
      return None

  def can_submit_more_jobs(self):
    if self.max_num_jobs and self.num_jobs >= self.max_num_jobs:
      print '[can_submit_more_jobs] can\'t submit any more jobs due to self.max_num_jobs =', self.max_num_jobs
      return False
    if not self.job_tracker.can_submit_more_jobs():
      print '[can_submit_more_jobs] can\'t submit any more jobs due to the job tracker'
      return False
    return True

  def run(self):
    r = redis.StrictRedis(host=self.redis_config['host'], port=self.redis_config['port'], db=self.redis_config['db'])
    p = r.pubsub(ignore_subscribe_messages=True)
    p.subscribe(self.redis_config['channel'])
    perf_file = open(os.path.join(self.working_dir, 'perf.txt'), 'w')
    self.num_jobs = 0
    while True:
      # Try to dispatch new jobs
      if self.can_submit_more_jobs():
        if self.start_job():
          self.num_jobs += 1
        else:
          print 'Done!'
          break
      else:
        # Check for results 
        print 'can\'t submit any more jobs, checking on current jobs'
        message = p.get_message()
        if message:
          print 'received message:', message
          (score, name, config) = self.parse_message(message['data'])
          print name, '/', config, 'finished successfully with a score', score
          item = self.name2item[name]
          perf_file.write("%f\t%s\t%s\n" % (score, name, config))
          perf_file.flush()
          self.config_q.observe_score(score, name, item)
          # Remove this jobs from dispatched
          if type(self.job_tracker) is LocalJobTracker: # for debugging
            print 'stopping', name, 'on local job tracker'
            self.job_tracker.set_job_done(name)
          try:
            self.dispatched.remove(name)
            print 'removed', name, 'from dispatched,', len(self.dispatched), 'still dispatched'
          except:
            print name + ' was not in dispatched, we gave up on this job as failed previously'
        else:
          # check if any jobs died
          print 'no one phoned home, maybe someone died?'
          r = set(self.job_tracker.jobs_running() + self.job_tracker.jobs_queued())
          print 'running and queued:', r
          failed = set([name for name in self.dispatched if name not in r])
          for name in failed:
            item = self.name2item[name]
            print 'dead:', name, item
            self.config_q.observe_score(FAILED_SCORE, name, item)
            self.dispatched.remove(name)
          else:
            print 'everything is running nicely:', len(r)
            time.sleep(self.poll_interval)
    perf_file.close()


class TemplateInfo(object):
  # TODO could support cardinalities on higher-order polynomials of features
  # (e.g. products of templates), just add more columns
  def __init__(self, filename):
    self.filename = filename
    self.__info = {}  # (templateName, stageName, syntaxMode) -> (cardinaityInt, timeFloat)
    self.__templates = set()
    self.__stages = set()
    with open(filename, 'r') as f:
      for line in f:
        toks = line.strip().split('\t')
        assert len(toks) == 5
        template, stage, syntax_mode, card, time = toks
        card = int(card)
        time = float(time)
        assert (template, stage, syntax_mode) not in self.__info
        self.__info[(template, stage, syntax_mode)] = (card, time)
        self.__templates.add(template)
        self.__stages.add(stage)
        #print template, stage, card, time
    self.__templates = list(self.__templates)
    self.__stages = list(self.__stages)
    if len(self.__stages) == 0:
      raise Exception('no stages?')

    # compute the set of (stage, templates) which have non-zero cardinality
    self.__nonzero = collections.defaultdict(list)  # stage -> [template]
    for (template, stage, syntax_mode), (card, time) in self.__info.iteritems():
      k = (stage, syntax_mode)
      if card > 0:
        self.__nonzero[k].append(template)
      else:
        print template, 'has no support in', k

    # stage -> [label/template]
    # if a stage appears here, only allow labels/templates to be chosen from this list
    self.__label_restrictions = {}

  def cardinality(self, template, stage, syntax_mode):
    k = (template, stage, syntax_mode)
    return self.__info[k][0]

  def stages(self):
    return self.__stages

  def restrict_stages_to(self, stages):
    self.__stages = list(set(self.__stages) & set(stages))
    if len(self.__stages) == 0:
      raise Exception('no stages left after intersecting with: ' + str(stages))

  def restrict_labels_for(self, stage, syntax_mode, labels):
    k = (stage, syntax_mode)
    assert not stage.endswith(syntax_mode)
    print '[restrict_labels_for]', k, 'to', labels
    self.__label_restrictions[k] = labels
    if len(self.__label_restrictions[k]) == 0:
      raise Exception('no labels available for: ' + str(k))

  def labels_for(self, stage, syntax_mode):
    ''' Returns a list of labels (templates) which can be used with the given stage '''
    k = (stage, syntax_mode)
    print '[labels_for]', k
    ret = []
    try:
      r = self.__label_restrictions[k]
      ret = list(set(r) & set(self.__nonzero[k]))
      print '[labels_for] INTERSECT(', r, ',', self.__nonzero[k], ') =', ret
    except:
      ret = self.__nonzero[k]
      print '[labels_for] nonzero =', self.__nonzero[k]
    if len(ret) == 0:
      print '__nonzero =', self.__nonzero.get(k)
      print '__label_restirctions =', self.__label_restrictions.get(k)
      raise Exception('no labels for ' + str(k))
    return ret

  def basic_templates(self):
    return self.__templates

def seeds(parser_mode, syntax_mode, settings):
  ''' Generator of Configs '''
  p = 10  # default number of training passes (this value is copied for all runs)
  if parser_mode == 'span':
    s1 = 'RoleSpanPruningStage'
    s2 = 'RoleSpanLabelingStage'
    reg = {s2: 10}
    batch_size = {s2: 1}
    passes = {s2: p}
    fs = [
      Feature(s2, syntax_mode, 'frameRoleArg', ['head1Word']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1LeftPos']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1FirstPos']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1LastPos']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1RightPos']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1Width/1']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1Width/2']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1Width/3']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1Width/4']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['Word-1-grams-between-Span1.First-and-Span1.Last']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['head1Pos', 'head2Pos']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['Dist(Len5,Span1.Last,Span2.First)']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['head1head2Path-LEMMA-DIRECTION-t']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['head1head2Path-POS-DEP-t']),
    ]
    if syntax_mode != 'regular':
      reg[s1] = 10
      batch_size[s1] = 1
      passes[s1] = p
      fs += [
        Feature(s1, syntax_mode, 'framePrune', ['span1LeftWord']),
        Feature(s1, syntax_mode, 'framePrune', ['span1FirstWord']),
        Feature(s1, syntax_mode, 'framePrune', ['span1LastWord']),
        Feature(s1, syntax_mode, 'framePrune', ['span1RightWord']),
        Feature(s1, syntax_mode, 'framePrune', ['span1Width/2']),
        Feature(s1, syntax_mode, 'framePrune', ['Dist(Len5,Span1.Last,Span2.First)']),
        Feature(s1, syntax_mode, 'span1IsConstituent', ['framePrune']),
        Feature(s1, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1FirstPos', 'span1LastPos', 'span1RightPos']),
        Feature(s1, syntax_mode, 'span1IsConstituent', ['span1Width/2', 'span1FirstPos', 'span1LastPos', 'span1RightPos']),
        Feature(s1, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1Width/2', 'span1LastPos', 'span1RightPos']),
        Feature(s1, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1FirstPos', 'span1Width/2', 'span1RightPos']),
        Feature(s1, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1FirstPos', 'span1LastPos', 'span1Width/2']),
        Feature(s2, syntax_mode, 'span1IsConstituent', ['frameRoleArg']),
        Feature(s2, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1FirstPos', 'span1LastPos', 'span1RightPos']),
        Feature(s2, syntax_mode, 'span1IsConstituent', ['span1Width/2', 'span1FirstPos', 'span1LastPos', 'span1RightPos']),
        Feature(s2, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1Width/2', 'span1LastPos', 'span1RightPos']),
        Feature(s2, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1FirstPos', 'span1Width/2', 'span1RightPos']),
        Feature(s2, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1FirstPos', 'span1LastPos', 'span1Width/2']),
      ]
    yield Config(FeatureSet(fs), settings, reg, batch_size, passes)
  elif parser_mode == 'head':
    s1 = 'RoleHeadStage'
    s2 = 'RoleHeadToSpanStage'
    yield Config(FeatureSet([
      Feature(s1, syntax_mode, 'frameRoleArg', ['head1Word']),
      Feature(s1, syntax_mode, 'frameRoleArg', ['head1Pos', 'head2Pos']),
      Feature(s1, syntax_mode, 'frameRoleArg', ['Dist(Len5,Span1.Last,Span2.First)']),
      Feature(s1, syntax_mode, 'frameRoleArg', ['head1head2Path-LEMMA-DIRECTION-t']),
      Feature(s1, syntax_mode, 'frameRoleArg', ['head1head2Path-POS-DEP-t']),
      Feature(s1, syntax_mode, 'head2GovHead1', ['frameRoleArg']),
      Feature(s1, syntax_mode, 'head2GovHead1', ['span1LeftPos', 'span1FirstPos', 'span1LastPos', 'span1RightPos']),
      Feature(s1, syntax_mode, 'head2GovHead1', ['span1Width/2', 'span1FirstPos', 'span1LastPos', 'span1RightPos']),
      Feature(s1, syntax_mode, 'head2GovHead1', ['span1LeftPos', 'span1Width/2', 'span1LastPos', 'span1RightPos']),
      Feature(s1, syntax_mode, 'head2GovHead1', ['span1LeftPos', 'span1FirstPos', 'span1Width/2', 'span1RightPos']),
      Feature(s1, syntax_mode, 'head2GovHead1', ['span1LeftPos', 'span1FirstPos', 'span1LastPos', 'span1Width/2']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1Width/1']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1Width/2', 'head1Pos']),
      Feature(s2, syntax_mode, 'frameRoleArg', ['span1Width/2', 'span1FirstPos']),
      Feature(s1, syntax_mode, 'span1IsConstituent', ['frameRoleArg']),
      Feature(s1, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1FirstPos', 'span1LastPos', 'span1RightPos']),
      Feature(s1, syntax_mode, 'span1IsConstituent', ['span1Width/2', 'span1FirstPos', 'span1LastPos', 'span1RightPos']),
      Feature(s1, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1Width/2', 'span1LastPos', 'span1RightPos']),
      Feature(s1, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1FirstPos', 'span1Width/2', 'span1RightPos']),
      Feature(s1, syntax_mode, 'span1IsConstituent', ['span1LeftPos', 'span1FirstPos', 'span1LastPos', 'span1Width/2']),
    ]), settings, {s1: 10, s2: 10}, {s1: 1, s2: 1}, {s1: p, s2: p})
  else:
    raise Exception('unknown parser_mode: ' + parser_mode)

# stages:
# FrameIdStage
# RoleHeadStage
# RoleHeadToSpanStage
# RoleSpanLabelingStage
# RoleSpanPruningStage

def experiments(template_info_filename, parser_mode, syntax_mode):
  ''' Returns a (TemplateInfo, [Config]) '''
  assert parser_mode in ['span', 'head']
  assert syntax_mode in ['regular', 'latent', 'none']
  stages = {
    'span': ['RoleSpanPruningStage', 'RoleSpanLabelingStage'],
    'head': ['RoleHeadStage', 'RoleHeadToSpanStage']
  }
  template_info = TemplateInfo(template_info_filename)
  settings = {
    'parserMode': parser_mode,
    'syntaxMode': syntax_mode,
    'evaluationFunction': 'ArgumentMicroF1',
  }
  s1, s2 = stages[parser_mode]
  if parser_mode == 'span' and syntax_mode == 'regular':
    template_info.restrict_stages_to([s2])
  else:
    template_info.restrict_stages_to([s1, s2])
  sd = list(seeds(parser_mode, syntax_mode, settings))
  labels = {
    ('RoleHeadStage', 'regular'): ['frameRole', 'frame'],
    ('RoleHeadStage', 'latent'): ['frameRole', 'frame', 'head2GovHead1'],
    ('RoleHeadStage', 'none'): ['frameRole', 'frame'],
    ('RoleHeadToSpanStage', 'regular'): ['frameRole', 'frame'],
    ('RoleHeadToSpanStage', 'latent'): ['frameRole', 'frame', 'span1IsConstituent'],
    ('RoleHeadToSpanStage', 'none'): ['frameRole', 'frame'],
    ('RoleSpanPruningStage', 'regular'): ['framePrune'],
    ('RoleSpanPruningStage', 'latent'): ['framePrune', 'head2GovHead1'],
    ('RoleSpanPruningStage', 'none'): ['framePrune'],
    ('RoleSpanLabelingStage', 'regular'): ['frameRoleArg', 'frameRole'],
    ('RoleSpanLabelingStage', 'latent'): ['frameRoleArg', 'frameRole', 'span1IsConstituent'],
    ('RoleSpanLabelingStage', 'none'): ['frameRoleArg', 'frameRole'],
  }
  template_info.restrict_labels_for(s1, syntax_mode, labels[(s1, syntax_mode)])
  template_info.restrict_labels_for(s2, syntax_mode, labels[(s2, syntax_mode)])
  return (template_info, sd)

def run_experiments(template_info_filename, ser_q_filename, deser_q_filename, parser_mode, syntax_mode, where):

  local = where == 'local'
  assert local or where == 'grid'

  # Run one of these at a time, otherwise caching gets messed up
  template_info, configs = experiments(template_info_filename, parser_mode, syntax_mode)
  #for template_info, configs in experiments(template_info_filename):
  print template_info
  print '\n\t'.join(str(c) for c in configs)

  global TEMPLATE_INFO
  TEMPLATE_INFO = template_info

  # Create the config queue
  if deser_q_filename == 'None':
    print 'creating empty config queue'
    # Right now the seed set is just each of the labels conjoined
    # with the headword. You can manually add some good seeds here if you know them.
    q = ConfigQueue(mutation_function=mutate_config, greediness=1.0)
    assert len(configs) > 0
    for conf in configs:
      q.seed(conf)
  else:
    print 'loading config queue from', deser_q_filename
    q = pickle.load(open(deser_q_filename, 'rb'))
    q.show_state()

  # Make sure config queue is setup to be saved on SIGINT
  global SER_Q_PATH
  global SER_Q
  if ser_q_filename != '/dev/null':
    print 'setting up to save to', ser_q_filename, 'on Ctr-C'
    SER_Q_PATH = ser_q_filename
    SER_Q = q
    def save_config_q_handler(signum, frame):
      ''' Function that saves the config queue on Ctr-C so that you can resume later '''
      if SER_Q is not None and SER_Q_PATH is not None:
        print 'saving config queue to', SER_Q_PATH
        pickle.dump(SER_Q, open(SER_Q_PATH, 'wb'))
      sys.exit(0)
    signal.signal(signal.SIGINT, save_config_q_handler)

  # Create the job tracker
  if local:
    jt = LocalJobTracker(debug=False, max_concurrent_jobs=2)
    jt.remove_all_jobs()
  else:
    jt = SgeJobTracker()

  #wd = 'experiments/forward-selection/role/span/regular'
  wd = os.path.join(
    'experiments/forward-selection/role',
    configs[0].params['parserMode'],
    configs[0].params['syntaxMode'])
  print 'working directory:', wd
  rc = {
    'channel': 'forward-selection',
    'host': socket.gethostname(),
    'port': '6379',
    'db': '0'
  }
  max_train = 30
  max_jobs = 5000
  fs = ForwardSelection('test', wd, jt, q, redis_config=rc,
    poll_interval=3.0, max_train_size=max_train, max_num_jobs=max_jobs)

  # TODO this is only here for development/debugging
  if not local:
    print 'cleanup...'
    os.system('rm logging/forward-selection/*')
    os.system('kill-all-jobs')
    time.sleep(2)
  print 'starting...'
  fs.run()

if __name__ == '__main__':

  # Make stdout flush regularly
  sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)

  if len(sys.argv) == 7:
    run_experiments(*(sys.argv[1:]))
  else:
    print 'please provide:'
    print '1) a path to a basic template cardinality file (e.g. experiments/forward-selection/basic-templates.txt)'
    print '2) a path to save the ConfigQueue to'
    print '3) a path to load the ConfigQueue from, or \"None\"'
    print '4) a parser mode (i.e. \"head\" or \"span\")'
    print '5) a syntax mode (i.e. \"regular\", \"latent\", or \"none\"'
    print '6) where to run (i.e. \"grid\" or \"local\")'
    sys.exit(-1)


# every experiment gets a human readable, but uniq name, e.g. 'frameId-forwardSelection-2014-10-09'
# every job gets a uniq id, a UUID
# the experiment name is used as a key in redis
# the values associated with it json that represent information about the run
# e.g. some run might be:
#{
#  jobId : '2b26c166-4f56-11e4-99fc-7c7a9146f5f0',
#  command : 'java -Xmx4G edu.jhu.hlt.fnparse.foo.Bar',
#  jar_hash : 'a5ff9934d159216c49a2b386edba062a15100907',
#  completed : '2014-10-09 01:24:09',
#  host : 'ch12',
#  params : {foo = 42, bar = 'baz'}
#  results : {targetMicroF1 = 0.733, runtime : 934.2}
#}




