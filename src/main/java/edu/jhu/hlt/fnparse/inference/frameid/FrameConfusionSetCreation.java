package edu.jhu.hlt.fnparse.inference.frameid;

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;

import com.google.common.collect.Iterators;

import edu.jhu.hlt.fnparse.data.FileFrameInstanceProvider;
import edu.jhu.hlt.fnparse.data.propbank.ParsePropbankData;
import edu.jhu.hlt.fnparse.data.propbank.PropbankReader;
import edu.jhu.hlt.fnparse.datatypes.FNParse;
import edu.jhu.hlt.fnparse.datatypes.FNTagging;
import edu.jhu.hlt.fnparse.datatypes.Frame;
import edu.jhu.hlt.fnparse.datatypes.FrameInstance;
import edu.jhu.hlt.fnparse.datatypes.Sentence;
import edu.jhu.hlt.fnparse.features.precompute.FeaturePrecomputation;
import edu.jhu.hlt.tutils.ExperimentProperties;
import edu.jhu.hlt.tutils.FileUtil;
import edu.jhu.hlt.tutils.Log;
import edu.jhu.hlt.tutils.Span;
import edu.jhu.hlt.tutils.TimeMarker;
import edu.jhu.prim.bimap.IntObjectBimap;
import edu.jhu.prim.tuple.Pair;

/**
 * List a subset of all possible frames for a given target.
 *
 * @author travis
 */
public class FrameConfusionSetCreation {

  /**
   * Reads the confusion set from disk and serves it up.
   */
  public static class FromDisk {
    Map<Pair<String, Span>, List<Integer>> sentTarget2frames;
    public FromDisk(File f) {
      Log.info("reading confusion sets from " + f.getPath());
      sentTarget2frames = new HashMap<>();
      try (BufferedReader r = FileUtil.getReader(f)) {
        for (String line = r.readLine(); line != null; line = r.readLine()) {
          String[] toks = line.split("\\s+");
          assert toks.length >= 3;
//          String docId = toks[0];
          String sentId = toks[1];
          Span target = Span.inverseShortString(toks[2]);

          List<Integer> frames = new ArrayList<>();
          for (int i = 3; i < toks.length; i++)
            frames.add(Integer.parseInt(toks[i]));

          Pair<String, Span> key = new Pair<>(sentId, target);
          List<Integer> old = sentTarget2frames.put(key, frames);
          assert old == null : "duplicate: " + key;
        }
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
      Log.info("done, read confusion sets for " + sentTarget2frames.size() + " targets");
    }
    /**
     * returns null if it hasn't been seen and empty list if there really are
     * no frame candidates.
     */
    public List<Integer> getCofusionSet(String sentId, Span target) {
      Pair<String, Span> key = new Pair<>(sentId, target);
      return sentTarget2frames.get(key);
    }
  }

  enum LexicalUnitType {
    WORD,
    WORD_AND_COARSE_POS,
    LEMMA_AND_COARSE_POS,
    LEMMA,
  }

  // Maps ("kill","V") -> [propbank/kill-v-1, propbank/kill-v-2, framenet/Murder...]
  // Key is generated by getKey
  private Map<String, List<Frame>> frames;
  private LexicalUnitType lexType;

  // Same as in FeaturePrecomputation, stores frameString <-> int
  private IntObjectBimap<String> kNames;

  public FrameConfusionSetCreation(LexicalUnitType lexType) {
    frames = new HashMap<>();
    this.lexType = lexType;
  }

  public String toString() {
    return String.format("<FCS %s LUs=%d frames=%d>", lexType, frames.size(), kNames.size());
  }

  /**
   * Provide a file like:
   * data/frameid/feb15a/raw-shards/job-0-of-256/role-names.txt.gz
   */
  public void readRoleNames(File knames) {
    Log.info("reading role names from " + knames.getPath());
    kNames = new IntObjectBimap<>();
    try (BufferedReader r = FileUtil.getReader(knames)) {
      String first = r.readLine();
      if (!"-1\tnoRole".equals(first))
        throw new RuntimeException("line=" + first);
      for (String line = r.readLine(); line != null; line = r.readLine()) {
        String[] toks = line.split("\\s+");
        int i = Integer.parseInt(toks[0]);
        int j = kNames.lookupIndex(toks[1], true);
        assert j == i;
      }
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
  }

  public List<Integer> possibleFrames(Sentence s, Span t) {
    String key = getKey(s, t);
    if (key == null) {
      Log.warn("can't handle this target: " + Arrays.toString(s.getWordFor(t)));
      return Collections.emptyList();
    }
    List<Frame> poss = frames.get(key);
    if (poss == null)
      return Collections.emptyList();
    List<Integer> l = new ArrayList<>();
    for (Frame f : poss) {
      String fs = "f=" + f.getName();
      int i = kNames.lookupIndex(fs, false);
      if (i < 0)
        throw new RuntimeException("couldn't find frame/role: " + fs);
      l.add(i);
    }
    return l;
  }

  public String getKey(Sentence s, Span t) {
    if (t.width() > 1) {
//      throw new RuntimeException("implement me");
      return null;
    }
    String word = s.getWord(t.start);
    String lemma = s.getLemma(t.start);
    String pos = s.getCoarsePos(t.start);
    switch (lexType) {
    case WORD:
      return word;
    case WORD_AND_COARSE_POS:
      return word + "." + pos;
    case LEMMA_AND_COARSE_POS:
      assert lemma != null;
      return lemma + "." + pos;
    case LEMMA:
      return lemma;
    }
    throw new RuntimeException("lexType=" + lexType);
  }

  public void addExamples(FNTagging y) {
    Sentence s = y.getSentence();
    int T = y.numFrameInstances();
    for (int i = 0; i < T; i++) {
      FrameInstance fi = y.getFrameInstance(i);
      String k = getKey(s, fi.getTarget());
      if (k == null) {
        Log.warn("can't handle this target: " + Arrays.toString(s.getWordFor(fi.getTarget())));
        continue;
      }
      List<Frame> l = frames.get(k);
      if (l == null) {
        l = new ArrayList<>();
        frames.put(k,  l);
      }
      if (!l.contains(fi.getFrame()))
        l.add(fi.getFrame());
    }
  }

  /**
   * Go over FN/TRAIN+LEX + PB/TRAIN+DEV and build lex->[frame] mapping.
   * Go over instances created by FeaturePrecomputation and emit lex->[frame]
   * 
   * Writes out in format:
   * <docId> <sentId> <target> <frame>*
   */
  public static void main(String[] args) throws IOException {
    ExperimentProperties config = ExperimentProperties.init(args);
    config.putIfAbsent("parseFN", "false");

    LexicalUnitType lut = LexicalUnitType.valueOf(
        config.getString("lexicalUnitType", LexicalUnitType.LEMMA_AND_COARSE_POS.name()));
    FrameConfusionSetCreation fcs = new FrameConfusionSetCreation(lut);
    fcs.readRoleNames(config.getExistingFile("roleNames"));
    File output = config.getFile("outputLex2Frames");

    // Read FN/LEX
    Iterator<FNTagging> iter = Collections.emptyIterator();
    iter = Iterators.concat(iter, FileFrameInstanceProvider.fn15lexFIP.getParsedOrTaggedSentences());
    iter = Iterators.concat(iter, FileFrameInstanceProvider.fn15trainFIP.getParsedOrTaggedSentences());
    ParsePropbankData.Redis autoParses = null;
    PropbankReader pbr = new PropbankReader(config, autoParses);
//    pbr.debug = true;
    iter = Iterators.concat(iter, pbr.getTrainDataStream().iterator());
    iter = Iterators.concat(iter, pbr.getDevDataStream().iterator());
    TimeMarker tm = new TimeMarker();
    int c = 0;
    while (iter.hasNext()) {
      FNTagging t = iter.next();
      fcs.addExamples(t);
      c++;
      if (tm.enoughTimePassed(15))
        Log.info("processed " + c + " parses, "+ fcs.toString());
    }

    Log.info("read " + c + " instances, about to write possible frames to " + output.getPath());

    boolean addParses = false;
    Iterable<FNParse> data = FeaturePrecomputation.getData("both", addParses);
    try (BufferedWriter w = FileUtil.getWriter(output)) {
      int out = 0;
      tm = new TimeMarker();
      Iterator<FNParse> itr = data.iterator();
      while (itr.hasNext()) {
        FNParse y = itr.next();
        out++;
        if (tm.enoughTimePassed(15))
          Log.info("output " + out + " sentences");
        Sentence s = y.getSentence();
        int n = s.size();
        for (int i = 0; i < n; i++) {
          Span t = Span.getSpan(i, i+1);
          List<Integer> frames = fcs.possibleFrames(s, t);
          FeaturePrecomputation.Target pre = new FeaturePrecomputation.Target(s.getId(), t);
          w.write(FeaturePrecomputation.Target.toLine(pre));
          for (int f : frames)
            w.write("\t" + f);
          w.newLine();
        }
      }
    }
    Log.info("done");
  }
}
